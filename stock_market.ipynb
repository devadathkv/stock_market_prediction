{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e333a6-221c-44da-a988-cea5a18cdaf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense, Dropout\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecae43eb-effc-4494-b8f1-88210ecb8549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (3.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (1.6.1)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: yfinance in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (0.2.64)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.5.0)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (76.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.73.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.14.0-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (4.3.6)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (3.18.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (4.13.3)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (0.11.4)\n",
      "Requirement already satisfied: websockets>=13.0 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (15.0.1)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from curl_cffi>=0.7->yfinance) (2025.1.31)\n",
      "Requirement already satisfied: rich in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.16.0-cp312-cp312-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\devad\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/376.0 MB 6.3 MB/s eta 0:01:00\n",
      "   ---------------------------------------- 2.6/376.0 MB 7.2 MB/s eta 0:00:52\n",
      "   ---------------------------------------- 4.5/376.0 MB 7.7 MB/s eta 0:00:49\n",
      "    --------------------------------------- 6.8/376.0 MB 8.6 MB/s eta 0:00:44\n",
      "    --------------------------------------- 9.2/376.0 MB 9.1 MB/s eta 0:00:41\n",
      "   - -------------------------------------- 11.5/376.0 MB 9.5 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 13.9/376.0 MB 9.7 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 16.0/376.0 MB 9.9 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 18.1/376.0 MB 9.9 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 20.4/376.0 MB 10.0 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 22.5/376.0 MB 10.0 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 24.9/376.0 MB 10.0 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 26.7/376.0 MB 10.0 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 28.8/376.0 MB 10.0 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 31.2/376.0 MB 10.0 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 33.3/376.0 MB 10.1 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 35.9/376.0 MB 10.1 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 38.0/376.0 MB 10.2 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 40.6/376.0 MB 10.3 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 43.0/376.0 MB 10.3 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 45.6/376.0 MB 10.4 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 48.0/376.0 MB 10.4 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 50.6/376.0 MB 10.5 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 53.2/376.0 MB 10.5 MB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 55.6/376.0 MB 10.6 MB/s eta 0:00:31\n",
      "   ------ --------------------------------- 57.9/376.0 MB 10.6 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 60.6/376.0 MB 10.7 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 62.9/376.0 MB 10.7 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 65.5/376.0 MB 10.7 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 67.9/376.0 MB 10.7 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 70.3/376.0 MB 10.8 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 72.9/376.0 MB 10.8 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 75.2/376.0 MB 10.8 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 77.6/376.0 MB 10.8 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 80.0/376.0 MB 10.9 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 82.3/376.0 MB 10.9 MB/s eta 0:00:28\n",
      "   --------- ------------------------------ 84.9/376.0 MB 10.9 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 87.3/376.0 MB 10.9 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 89.7/376.0 MB 10.9 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 92.0/376.0 MB 10.9 MB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 94.6/376.0 MB 10.9 MB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 97.0/376.0 MB 11.0 MB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 99.4/376.0 MB 11.0 MB/s eta 0:00:26\n",
      "   ---------- ---------------------------- 101.7/376.0 MB 11.0 MB/s eta 0:00:25\n",
      "   ---------- ---------------------------- 104.1/376.0 MB 11.0 MB/s eta 0:00:25\n",
      "   ----------- --------------------------- 106.7/376.0 MB 11.0 MB/s eta 0:00:25\n",
      "   ----------- --------------------------- 109.1/376.0 MB 11.0 MB/s eta 0:00:25\n",
      "   ----------- --------------------------- 111.4/376.0 MB 11.0 MB/s eta 0:00:24\n",
      "   ----------- --------------------------- 114.0/376.0 MB 11.0 MB/s eta 0:00:24\n",
      "   ------------ -------------------------- 116.4/376.0 MB 11.1 MB/s eta 0:00:24\n",
      "   ------------ -------------------------- 119.0/376.0 MB 11.1 MB/s eta 0:00:24\n",
      "   ------------ -------------------------- 121.4/376.0 MB 11.1 MB/s eta 0:00:23\n",
      "   ------------ -------------------------- 124.0/376.0 MB 11.1 MB/s eta 0:00:23\n",
      "   ------------- ------------------------- 126.4/376.0 MB 11.1 MB/s eta 0:00:23\n",
      "   ------------- ------------------------- 129.0/376.0 MB 11.1 MB/s eta 0:00:23\n",
      "   ------------- ------------------------- 131.3/376.0 MB 11.1 MB/s eta 0:00:23\n",
      "   ------------- ------------------------- 133.7/376.0 MB 11.1 MB/s eta 0:00:22\n",
      "   -------------- ------------------------ 136.1/376.0 MB 11.1 MB/s eta 0:00:22\n",
      "   -------------- ------------------------ 138.7/376.0 MB 11.1 MB/s eta 0:00:22\n",
      "   -------------- ------------------------ 141.3/376.0 MB 11.1 MB/s eta 0:00:22\n",
      "   -------------- ------------------------ 143.7/376.0 MB 11.2 MB/s eta 0:00:21\n",
      "   --------------- ----------------------- 146.3/376.0 MB 11.2 MB/s eta 0:00:21\n",
      "   --------------- ----------------------- 148.6/376.0 MB 11.2 MB/s eta 0:00:21\n",
      "   --------------- ----------------------- 151.0/376.0 MB 11.2 MB/s eta 0:00:21\n",
      "   --------------- ----------------------- 153.6/376.0 MB 11.2 MB/s eta 0:00:20\n",
      "   ---------------- ---------------------- 155.7/376.0 MB 11.2 MB/s eta 0:00:20\n",
      "   ---------------- ---------------------- 157.8/376.0 MB 11.1 MB/s eta 0:00:20\n",
      "   ---------------- ---------------------- 159.4/376.0 MB 11.1 MB/s eta 0:00:20\n",
      "   ---------------- ---------------------- 160.7/376.0 MB 11.0 MB/s eta 0:00:20\n",
      "   ---------------- ---------------------- 162.8/376.0 MB 11.0 MB/s eta 0:00:20\n",
      "   ----------------- --------------------- 165.2/376.0 MB 11.0 MB/s eta 0:00:20\n",
      "   ----------------- --------------------- 167.5/376.0 MB 11.0 MB/s eta 0:00:19\n",
      "   ----------------- --------------------- 169.9/376.0 MB 11.0 MB/s eta 0:00:19\n",
      "   ----------------- --------------------- 172.2/376.0 MB 11.0 MB/s eta 0:00:19\n",
      "   ------------------ -------------------- 174.9/376.0 MB 11.0 MB/s eta 0:00:19\n",
      "   ------------------ -------------------- 177.2/376.0 MB 11.0 MB/s eta 0:00:19\n",
      "   ------------------ -------------------- 179.8/376.0 MB 11.0 MB/s eta 0:00:18\n",
      "   ------------------ -------------------- 182.2/376.0 MB 11.0 MB/s eta 0:00:18\n",
      "   ------------------- ------------------- 184.5/376.0 MB 11.0 MB/s eta 0:00:18\n",
      "   ------------------- ------------------- 186.9/376.0 MB 11.1 MB/s eta 0:00:18\n",
      "   ------------------- ------------------- 189.5/376.0 MB 11.1 MB/s eta 0:00:17\n",
      "   ------------------- ------------------- 191.9/376.0 MB 11.1 MB/s eta 0:00:17\n",
      "   -------------------- ------------------ 194.5/376.0 MB 11.1 MB/s eta 0:00:17\n",
      "   -------------------- ------------------ 196.9/376.0 MB 11.1 MB/s eta 0:00:17\n",
      "   -------------------- ------------------ 199.2/376.0 MB 11.1 MB/s eta 0:00:16\n",
      "   -------------------- ------------------ 201.6/376.0 MB 11.1 MB/s eta 0:00:16\n",
      "   --------------------- ----------------- 203.7/376.0 MB 11.1 MB/s eta 0:00:16\n",
      "   --------------------- ----------------- 206.0/376.0 MB 11.1 MB/s eta 0:00:16\n",
      "   --------------------- ----------------- 208.7/376.0 MB 11.1 MB/s eta 0:00:16\n",
      "   --------------------- ----------------- 211.3/376.0 MB 11.1 MB/s eta 0:00:15\n",
      "   ---------------------- ---------------- 213.6/376.0 MB 11.1 MB/s eta 0:00:15\n",
      "   ---------------------- ---------------- 216.0/376.0 MB 11.1 MB/s eta 0:00:15\n",
      "   ---------------------- ---------------- 218.6/376.0 MB 11.1 MB/s eta 0:00:15\n",
      "   ---------------------- ---------------- 221.0/376.0 MB 11.1 MB/s eta 0:00:14\n",
      "   ----------------------- --------------- 223.3/376.0 MB 11.1 MB/s eta 0:00:14\n",
      "   ----------------------- --------------- 226.0/376.0 MB 11.1 MB/s eta 0:00:14\n",
      "   ----------------------- --------------- 228.3/376.0 MB 11.1 MB/s eta 0:00:14\n",
      "   ----------------------- --------------- 230.7/376.0 MB 11.1 MB/s eta 0:00:14\n",
      "   ------------------------ -------------- 233.0/376.0 MB 11.1 MB/s eta 0:00:13\n",
      "   ------------------------ -------------- 235.4/376.0 MB 11.1 MB/s eta 0:00:13\n",
      "   ------------------------ -------------- 237.8/376.0 MB 11.1 MB/s eta 0:00:13\n",
      "   ------------------------ -------------- 240.4/376.0 MB 11.1 MB/s eta 0:00:13\n",
      "   ------------------------- ------------- 242.5/376.0 MB 11.1 MB/s eta 0:00:12\n",
      "   ------------------------- ------------- 244.8/376.0 MB 11.1 MB/s eta 0:00:12\n",
      "   ------------------------- ------------- 247.5/376.0 MB 11.1 MB/s eta 0:00:12\n",
      "   ------------------------- ------------- 249.8/376.0 MB 11.1 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 251.9/376.0 MB 11.1 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 254.5/376.0 MB 11.1 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 256.6/376.0 MB 11.1 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 259.0/376.0 MB 11.1 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 261.4/376.0 MB 11.1 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 263.7/376.0 MB 11.2 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 266.1/376.0 MB 11.2 MB/s eta 0:00:10\n",
      "   --------------------------- ----------- 268.4/376.0 MB 11.2 MB/s eta 0:00:10\n",
      "   ---------------------------- ---------- 270.8/376.0 MB 11.2 MB/s eta 0:00:10\n",
      "   ---------------------------- ---------- 273.4/376.0 MB 11.2 MB/s eta 0:00:10\n",
      "   ---------------------------- ---------- 275.8/376.0 MB 11.2 MB/s eta 0:00:09\n",
      "   ---------------------------- ---------- 278.1/376.0 MB 11.2 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 280.5/376.0 MB 11.2 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 282.9/376.0 MB 11.2 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 285.2/376.0 MB 11.2 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 287.6/376.0 MB 11.2 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 289.9/376.0 MB 11.3 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 292.3/376.0 MB 11.3 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 294.9/376.0 MB 11.3 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 297.3/376.0 MB 11.3 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 299.6/376.0 MB 11.3 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 302.0/376.0 MB 11.3 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 304.3/376.0 MB 11.3 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 307.0/376.0 MB 11.3 MB/s eta 0:00:07\n",
      "   -------------------------------- ------ 309.3/376.0 MB 11.3 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 311.7/376.0 MB 11.3 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 314.3/376.0 MB 11.3 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 316.7/376.0 MB 11.3 MB/s eta 0:00:06\n",
      "   --------------------------------- ----- 319.0/376.0 MB 11.3 MB/s eta 0:00:06\n",
      "   --------------------------------- ----- 321.4/376.0 MB 11.3 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 324.0/376.0 MB 11.3 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 326.4/376.0 MB 11.3 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 329.0/376.0 MB 11.3 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 331.4/376.0 MB 11.3 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 333.7/376.0 MB 11.3 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 336.3/376.0 MB 11.3 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 339.0/376.0 MB 11.3 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 341.3/376.0 MB 11.3 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 343.9/376.0 MB 11.3 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 346.3/376.0 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 348.9/376.0 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 351.3/376.0 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 353.9/376.0 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 356.3/376.0 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 358.6/376.0 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 361.0/376.0 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 363.3/376.0 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 366.0/376.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  368.3/376.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  370.9/376.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  373.3/376.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 376.0/376.0 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.4/12.6 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.7/12.6 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.6 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 11.3 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.73.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 2.4/4.3 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading h5py-3.14.0-cp312-cp312-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   -------------------------------- ------- 2.4/2.9 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 11.1 MB/s eta 0:00:00\n",
      "Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.4/26.4 MB 12.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.7/26.4 MB 11.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 7.1/26.4 MB 11.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.7/26.4 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.1/26.4 MB 11.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 14.4/26.4 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 17.0/26.4 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.4/26.4 MB 11.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.8/26.4 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.1/26.4 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.16.0-cp312-cp312-win_amd64.whl (315 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, termcolor, tensorboard-data-server, optree, opt-einsum, numpy, markdown, grpcio, google-pasta, gast, absl-py, tensorboard, ml-dtypes, h5py, astunparse, keras, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.3\n",
      "    Uninstalling numpy-2.2.3:\n",
      "      Successfully uninstalled numpy-2.2.3\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.73.1 h5py-3.14.0 keras-3.10.0 libclang-18.1.1 markdown-3.8.2 ml-dtypes-0.5.1 namex-0.1.0 numpy-2.1.3 opt-einsum-3.4.0 optree-0.16.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.1.0 wheel-0.45.1 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\devad\\AppData\\Roaming\\Python\\Python312\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\devad\\AppData\\Roaming\\Python\\Python312\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas matplotlib scikit-learn tensorflow yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a6def5-5539-4a47-9fd8-c22ffcdef729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd570b07-a80c-4e27-b021-abbf91f511b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stock_symbol, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Load stock data from Yahoo Finance\n",
    "    You can replace this with your own data source\n",
    "    \"\"\"\n",
    "    import yfinance as yf\n",
    "    df = yf.download(stock_symbol, start=start_date, end=end_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae66f751-8ba6-42c9-a1da-4678d1ce479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, look_back=60, train_size=0.8):\n",
    "    \"\"\"\n",
    "    Preprocess data for LSTM:\n",
    "    - Use 'Close' price\n",
    "    - Scale data to 0-1 range\n",
    "    - Create sequences for LSTM\n",
    "    - Split into train/test sets\n",
    "    \"\"\"\n",
    "    # Use Close price\n",
    "    data = df.filter(['Close']).values\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    \n",
    "    # Create training data\n",
    "    train_len = int(len(scaled_data) * train_size)\n",
    "    train_data = scaled_data[0:train_len, :]\n",
    "    \n",
    "    # Create sequences\n",
    "    X_train, y_train = [], []\n",
    "    for i in range(look_back, len(train_data)):\n",
    "        X_train.append(train_data[i-look_back:i, 0])\n",
    "        y_train.append(train_data[i, 0])\n",
    "    \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    \n",
    "    # Create testing data\n",
    "    test_data = scaled_data[train_len - look_back:, :]\n",
    "    X_test, y_test = [], scaled_data[train_len:, :]\n",
    "    for i in range(look_back, len(test_data)):\n",
    "        X_test.append(test_data[i-look_back:i, 0])\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83825bf5-b508-4ecc-b51b-c0fbd5467180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Build LSTM Model\n",
    "def build_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Build and compile LSTM model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First LSTM layer\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Second LSTM layer\n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Third LSTM layer\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "905fdcef-091c-4a96-8d47-9e1727dc1cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Train Model\n",
    "def train_model(model, X_train, y_train, epochs=100, batch_size=32):\n",
    "    \"\"\"\n",
    "    Train the LSTM model with early stopping\n",
    "    \"\"\"\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "239399df-4c7b-434a-9b5c-06f50b9b29c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Evaluate Model\n",
    "def evaluate_model(model, X_test, y_test, scaler):\n",
    "    \"\"\"\n",
    "    Make predictions and evaluate model performance\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    # Inverse transform actual values\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    print(f'Test RMSE: {rmse:.2f}')\n",
    "    \n",
    "    return predictions, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6464829-2589-4666-a00b-55caa74631df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b38575ee-4c41-4e29-9538-f7213db8ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(train, test, predictions):\n",
    "    \"\"\"\n",
    "    Plot training data, test data, and predictions\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.title('Stock Price Prediction')\n",
    "    plt.xlabel('Date', fontsize=18)\n",
    "    plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "    \n",
    "    # Plot training data\n",
    "    train_len = len(train)\n",
    "    plt.plot(train['Close'], label='Training Data')\n",
    "    \n",
    "    # Plot test data\n",
    "    test_len = len(test)\n",
    "    plt.plot(test.index, test['Close'], label='Actual Price')\n",
    "    \n",
    "    # Plot predictions\n",
    "    plt.plot(test.index, predictions, label='Predicted Price')\n",
    "    \n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7218d3f1-6feb-4f0f-af1c-cdebb7fb2748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devad\\AppData\\Local\\Temp\\ipykernel_41620\\3077839406.py:7: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(stock_symbol, start=start_date, end=end_date)\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(3272, 0)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m df = load_data(STOCK_SYMBOL, START_DATE, END_DATE)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Step 2: Preprocess data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m X_train, y_train, X_test, y_test, scaler = \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOOK_BACK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Step 3: Build model\u001b[39;00m\n\u001b[32m     17\u001b[39m model = build_lstm_model((X_train.shape[\u001b[32m1\u001b[39m], \u001b[32m1\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mpreprocess_data\u001b[39m\u001b[34m(df, look_back, train_size)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Scale data\u001b[39;00m\n\u001b[32m     13\u001b[39m scaler = MinMaxScaler(feature_range=(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m scaled_data = \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Create training data\u001b[39;00m\n\u001b[32m     17\u001b[39m train_len = \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(scaled_data) * train_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:918\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    903\u001b[39m         warnings.warn(\n\u001b[32m    904\u001b[39m             (\n\u001b[32m    905\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    914\u001b[39m         )\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\preprocessing\\_data.py:447\u001b[39m, in \u001b[36mMinMaxScaler.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    445\u001b[39m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;28mself\u001b[39m._reset()\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\preprocessing\\_data.py:487\u001b[39m, in \u001b[36mMinMaxScaler.partial_fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    484\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m    486\u001b[39m first_pass = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mn_samples_seen_\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_array_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    495\u001b[39m data_min = _array_api._nanmin(X, axis=\u001b[32m0\u001b[39m, xp=xp)\n\u001b[32m    496\u001b[39m data_max = _array_api._nanmax(X, axis=\u001b[32m0\u001b[39m, xp=xp)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1139\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1137\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n\u001b[32m   1138\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_features < ensure_min_features:\n\u001b[32m-> \u001b[39m\u001b[32m1139\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1140\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m feature(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1141\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m a minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1142\u001b[39m             % (n_features, array.shape, ensure_min_features, context)\n\u001b[32m   1143\u001b[39m         )\n\u001b[32m   1145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_non_negative:\n\u001b[32m   1146\u001b[39m     whom = input_name\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 feature(s) (shape=(3272, 0)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    STOCK_SYMBOL = 'AAPL'  # Example: Apple stock\n",
    "    START_DATE = '2010-01-01'\n",
    "    END_DATE = '2023-01-01'\n",
    "    LOOK_BACK = 60  # Number of previous days to use for prediction\n",
    "    EPOCHS = 100\n",
    "    BATCH_SIZE = 32\n",
    "    \n",
    "    # Step 1: Load data\n",
    "    df = load_data(STOCK_SYMBOL, START_DATE, END_DATE)\n",
    "    \n",
    "    # Step 2: Preprocess data\n",
    "    X_train, y_train, X_test, y_test, scaler = preprocess_data(df, LOOK_BACK)\n",
    "    \n",
    "    # Step 3: Build model\n",
    "    model = build_lstm_model((X_train.shape[1], 1))\n",
    "    \n",
    "    # Step 4: Train model\n",
    "    model, history = train_model(model, X_train, y_train, EPOCHS, BATCH_SIZE)\n",
    "    \n",
    "    # Step 5: Evaluate model\n",
    "    predictions, y_test = evaluate_model(model, X_test, y_test, scaler)\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    train = df[:int(len(df)*0.8)]\n",
    "    test = df[int(len(df)*0.8):]\n",
    "    test['Predictions'] = predictions\n",
    "    \n",
    "    # Step 6: Plot results\n",
    "    plot_results(train, test, test['Predictions'])\n",
    "    \n",
    "    # Optional: Save model\n",
    "    model.save('stock_price_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642249bd-44f4-48a5-83b7-879bdb4fa65b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf8353-a277-44b7-b569-cf519af9d345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
